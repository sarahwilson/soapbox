# Quality as a Mission

About 7 years ago my favourite Dave (just kidding, you’re all my favourite) was telling me about how Westjet had set up their product teams not based on customer segment or user role or a part of the product but based on a mission, for example, Day of Travel. So the team was responsible for any and all functions that might be required on that day for WJ’s passengers. I’m going to guess there were teams for the before and the after, but what resonated with me is that the team had been given a mission that was obviously never complete, never done. There isn’t anything that points at a particular solution to limit the team’s innovation and so everything is on the table. In that setup, there will always be things to be investigated and hypothesized, experimented and validated and then assessed and improved all over again. Plus you’ve dropped the team right into the customers’ shoes to build that vastly important customer empathy as they think about the travel horror stories we all know and share.

Many years on from that conversation, I’ve been thinking about how to infuse that kind of sentiment into teams. How can I create something that encourages quality to be viewed as a mission when balanced with the needs of the business (read: getting things done quickly to make money). Halfway into my career, here’s what I’ve got so far:
1. Customers can't find bugs.
- With this kind of enduring metric, I would expect to see the following behaviours and attitudes:
  - Teams know that bugs impact customers negatively which in turn affects the business. (If you have people who don’t care if customers are impacted negatively, you are doing many, many things wrong. DM me for my consultancy rates. We can talk about my flexible payment plans.)
  - Teams realize that the level of manual testing required to ensure customers don’t find bugs would be ridiculous and therefore automation is the way. Automation is the way.
  - When customers do find bugs, teams are motivated to look into what went wrong and put mitigations in place so that it doesn’t happen again.
  - Learning is celebrated and mistakes aren’t punished. We’re all people just trying to do our best work. Learning from mistakes and incorrect assumptions is vital for innovation and growth and applies to our businesses and us as individuals.

2. Your stakeholders should know exactly where they need to go to learn everything about the state of quality for the work you produce.
- With this kind of enduring metric, I would expect to see the following behaviours and attitudes:
  - Teams will have to create and revisit data that they believe indicates a level of quality - maybe it’s unit test coverage, maybe it’s the failure rate on the end-to-end automation that’s been built, maybe it’s load times for specific pages - whatever it is, teams will have to consider it within their own current context and the wider goals of the company at that point in time.
  - Because teams have to produce this data, they can use it with the team to adjust priorities. If a particular number is different this month, maybe a bit of time should be spent to improve it. Or maybe not. It will be balanced against other priorities and other metrics.
  - Because the information is readily available, teams can look to see what other teams are sharing and contemplate if that’s something they should be measuring too. Cross-team pollination is your friend.
  - Because teams know that stakeholders and other parties external to the team might be looking at the data, it’s highly likely that they will stay on top of where their numbers are at. I am going to go to the gym today. Look for my update on Strava, accountability buddy.
  - Stakeholders are given visibility into what the team deems valuable and can suggest other metrics the team might not have considered, increasing understanding of what is important across the organization at that time.
  - Stakeholders can ask critical questions and learn more about the challenges that a team might be facing. This can affect hiring decisions, team shuffles, shelling out for tooling or employee training, etc.

Of course there are some iterations here. There isn’t much point on focusing on a typo in your UI when you have daily outages. So maybe your first crack at this is “Customers don’t experience outages.” Great. Start there. Fix that to the degree you need and then move the bar to include bugs in critical areas of your product or for your most VIP-est of customers. And you don’t need to have a shiny dashboard to show off a team’s quality metrics. It can be a weekly Slack message that gets posted where everyone can see it, showing week-over-week changes. The important thing is that the information is shared and valued by all.

So that’s what I’ve got. I’m excited to see how my thinking will change and evolve over the next 20 years and see what I’ve got completely wrong. What have you seen that’s worked or failed miserably when it comes to driving quality?
